{"cells":[{"cell_type":"code","execution_count":null,"id":"c0d7acf1-8591-463e-b815-66258f83ed7f","metadata":{"id":"c0d7acf1-8591-463e-b815-66258f83ed7f"},"outputs":[],"source":["from datasets import load_dataset\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"a0ab712f-c370-4162-afe2-adcacb2a9cfd","metadata":{"id":"a0ab712f-c370-4162-afe2-adcacb2a9cfd","outputId":"1f05a520-4fa7-43e3-953f-1e1b300603d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["++++++Reading the Dataset++++++++++\n"]}],"source":["print(\"++++++Reading the Dataset++++++++++\")\n","dataset = load_dataset(\"Anonymous/Final_idiom_all\",split='train') ######### please change the dataset in to the given csv file"]},{"cell_type":"code","execution_count":null,"id":"06d38808-f5d0-4069-8e03-a83a3e17ab66","metadata":{"id":"06d38808-f5d0-4069-8e03-a83a3e17ab66"},"outputs":[],"source":["from huggingface_hub import login\n","\n","login(token='Anonymous_uihhuiguu9')"]},{"cell_type":"code","execution_count":null,"id":"b4cec1c6-af32-485f-a7a9-f8adf6757c6f","metadata":{"id":"b4cec1c6-af32-485f-a7a9-f8adf6757c6f"},"outputs":[],"source":["system_message='''You are an polyglot, who are having exceptional linguistic and cultural domain knowledge. Also, you are an native speaker of hindi, bengali and thai.'''"]},{"cell_type":"code","execution_count":null,"id":"e6e8e226-f1af-44e4-9ec6-e84ba7484747","metadata":{"id":"e6e8e226-f1af-44e4-9ec6-e84ba7484747"},"outputs":[],"source":["def format_data(sample):\n","    return [\n","        {\n","            \"role\": \"system\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": system_message\n","                }\n","            ],\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"image\",\n","                    \"image\": sample[\"image\"],\n","                },\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": sample['Actual idiom'],\n","                }\n","            ],\n","        },\n","        {\n","            \"role\": \"assistant\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": sample[\"Descriptive Meaning(Human Annotation)\"]\n","                }\n","            ],\n","        },\n","    ]"]},{"cell_type":"code","execution_count":null,"id":"5d62db64-f863-451a-b8f5-29e286306707","metadata":{"id":"5d62db64-f863-451a-b8f5-29e286306707","outputId":"277f2b66-c55c-4556-d838-04f970cd448e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['image', 'Actual idiom', 'Literal Translation', 'English Pronounciation', 'Idiom meaning in English', 'Descriptive Meaning(Human Annotation)'],\n","    num_rows: 3533\n","})\n"]}],"source":["print(dataset)"]},{"cell_type":"code","execution_count":null,"id":"98e26f04-7523-48d2-b85f-c8737831eb85","metadata":{"id":"98e26f04-7523-48d2-b85f-c8737831eb85","outputId":"b43d5aad-d978-4812-810c-27900be787a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7EFF2912CAC0>, 'Actual idiom': 'นอนเป็นท้าวกุมภัณฑ์', 'Literal Translation': 'Sleep as a lord of the garuda', 'English Pronounciation': 'Non pen thao kumphan', 'Idiom meaning in English': \"Keep sleeping and don't want to wake up.\", 'Descriptive Meaning(Human Annotation)': 'The Thai idiom \"นอนเป็นท้าวกุมภัณฑ์\" translates to \"sleeping like a giant\" in English. It describes someone who sleeps very deeply and soundly, often implying that they are difficult to wake up. The imagery evokes a sense of a large, powerful being in a state of complete rest, undisturbed by the world around them.'}\n","3533\n"]}],"source":["# print(dataset[3132])\n","# print(len(dataset))"]},{"cell_type":"code","execution_count":null,"id":"cba40892-aa71-4186-9386-06bc31e0b481","metadata":{"id":"cba40892-aa71-4186-9386-06bc31e0b481","outputId":"94e0955e-0612-4899-f5be-2f21df468a32"},"outputs":[{"name":"stdout","output_type":"stream","text":["++++++Seperating the Dataset on Lingual Basis++++++++++\n"]}],"source":["print(\"++++++Seperating the Dataset on Lingual Basis++++++++++\")\n","dataset_hindi = dataset.select(range(0,1277))\n","dataset_thai = dataset.select(range(1382,3133))\n","bengali_indicies = list(range(1277,1382))+list(range(3133,3533))\n","dataset_bengali= dataset.select(bengali_indicies)"]},{"cell_type":"code","execution_count":null,"id":"b3f3186b-4da4-44b5-98d9-cb35f41b2d51","metadata":{"id":"b3f3186b-4da4-44b5-98d9-cb35f41b2d51"},"outputs":[],"source":["from datasets import Dataset,concatenate_datasets"]},{"cell_type":"code","execution_count":null,"id":"6b9fc488-0948-4e31-8beb-70ccaf1838f5","metadata":{"id":"6b9fc488-0948-4e31-8beb-70ccaf1838f5"},"outputs":[],"source":["def split_dataset(dataset1):\n","    train_testvalid = dataset1.train_test_split(test_size=0.3, seed=42)\n","    train_dataset = train_testvalid['train']\n","    temp_dataset = train_testvalid['test']\n","\n","    # Step 2: Split the remaining 30% into 2/3 (validation) and 1/3 (test)\n","    # 2/3 of 30% = 20%, 1/3 of 30% = 10%\n","    val_test = temp_dataset.train_test_split(test_size=2/3, seed=42)\n","    val_dataset = val_test['train']    # 20%\n","    test_dataset = val_test['test']    # 10%\n","\n","    return train_dataset, val_dataset, test_datasets"]},{"cell_type":"code","execution_count":null,"id":"008173e7-07f3-44f8-a90d-81ec70f3a187","metadata":{"id":"008173e7-07f3-44f8-a90d-81ec70f3a187","outputId":"df38d1fd-0c50-4248-e703-3e2c9b5c6787"},"outputs":[{"name":"stdout","output_type":"stream","text":["2471 353 709\n"]}],"source":["print(\"++++++Splitting the Dataset and Merging++++++++++\")\n","train_dataset_hindi, val_dataset_hindi, test_dataset_hindi = split_dataset(dataset_hindi)\n","train_dataset_thai, val_dataset_thai, test_dataset_thai = split_dataset(dataset_thai)\n","train_dataset_bengali, val_dataset_bengali, test_dataset_bengali = split_dataset(dataset_bengali)\n","\n","\n","# Merging the dataset\n","train_dataset_final = concatenate_datasets([train_dataset_hindi,train_dataset_thai,train_dataset_bengali])\n","val_dataset_final = concatenate_datasets([val_dataset_hindi,val_dataset_thai,val_dataset_bengali])\n","test_dataset_final = concatenate_datasets([test_dataset_hindi,test_dataset_thai,test_dataset_bengali])\n","\n","print(len(train_dataset_final),len(val_dataset_final),len(test_dataset_final))\n","\n","\n","dataset.save_to_disk(\"test_dataset\")"]},{"cell_type":"code","execution_count":null,"id":"6c278b2e-0698-4ed3-a873-3f34b67380f7","metadata":{"id":"6c278b2e-0698-4ed3-a873-3f34b67380f7"},"outputs":[],"source":["print(\"++++++Converting the Dataset to JSON format++++++++++\")\n","train_dataset = [format_data(sample) for sample in train_dataset]\n","eval_dataset = [format_data(sample) for sample in val_dataset]\n","test_dataset = [format_data(sample) for sample in test_dataset]"]},{"cell_type":"code","execution_count":null,"id":"fbba9081-ca0e-4455-bfc0-c8a1bce4cc33","metadata":{"id":"fbba9081-ca0e-4455-bfc0-c8a1bce4cc33","outputId":"f905073d-3bac-4fa1-cf5f-a61c49acc375"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'role': 'system', 'content': [{'type': 'text', 'text': 'You are an polyglot, who are having exceptional linguistic and cultural domain knowledge. Also, you are an native speaker of hindi, bengali and thai.'}]}, {'role': 'user', 'content': [{'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7EFF2837F7F0>}, {'type': 'text', 'text': 'ย้ายสำมะโนครัวไปอยู่ในคุก'}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': \"The Thai idiom 'ย้ายสำมะโนครัวไปอยู่ในคุก' translates to 'Moving the household registry to prison' in English. This idiom is used to describe a situation where someone is constantly in trouble or frequently ends up in jail, to the point where it seems like their permanent residence is in prison. It conveys the idea of habitual wrongdoing or a continuous cycle of criminal behavior. \\n\\nFor an image based on this idiom, you might depict a family or household items being moved into a prison cell, symbolizing the notion of making the prison their home.\"}]}]\n"]}],"source":["print(train_dataset[2000])"]},{"cell_type":"code","execution_count":null,"id":"4f8aca81-a2b5-4028-92dd-96c59f2e16a2","metadata":{"id":"4f8aca81-a2b5-4028-92dd-96c59f2e16a2"},"outputs":[],"source":["# import torch\n","# from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor\n","print(\"++++++Importing Models++++++++++\")\n","model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n","from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor, Qwen2_5_VLProcessor\n","from qwen_vl_utils import process_vision_info\n","import torch"]},{"cell_type":"markdown","source":[],"metadata":{"id":"0R2qtqkhfPH8"},"id":"0R2qtqkhfPH8"},{"cell_type":"code","execution_count":null,"id":"6e9b0cc2-4f57-4966-9d07-a776ea51f08a","metadata":{"colab":{"referenced_widgets":["693a4c9dc15849439f5b7f6eb6789f59"]},"id":"6e9b0cc2-4f57-4966-9d07-a776ea51f08a","outputId":"72d9c9ab-c606-40ac-bf39-be396fcdb743"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"693a4c9dc15849439f5b7f6eb6789f59","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"]}],"source":["print(\"++++++setting up BitsAndBytesConfig++++++++++\")\n","from transformers import BitsAndBytesConfig\n","\n","# BitsAndBytesConfig int-4 config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# Load model and tokenizer\n","model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n","    model_id,\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n","    quantization_config=bnb_config\n",")\n","processor = AutoProcessor.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":null,"id":"afd3eadf-2261-4f73-8014-88a852ed8fe3","metadata":{"id":"afd3eadf-2261-4f73-8014-88a852ed8fe3","outputId":"16f4b93a-4a1a-4513-c3bb-bd476967061f"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 2,523,136 || all params: 8,294,689,792 || trainable%: 0.0304\n"]}],"source":["print(\"++++++Configuring LoRA and peft++++++++++\")\n","from peft import LoraConfig, get_peft_model\n","\n","# Configure LoRA\n","peft_config = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0.05,\n","    r=8,\n","    bias=\"none\",\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","# Apply PEFT model adaptation\n","peft_model = get_peft_model(model, peft_config)\n","\n","# Print trainable parameters\n","peft_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"id":"d542e73b-bd14-4b7d-b74e-2f57b6803e71","metadata":{"id":"d542e73b-bd14-4b7d-b74e-2f57b6803e71"},"outputs":[],"source":["from trl import SFTConfig\n","\n","# Configure training arguments\n","training_args = SFTConfig(\n","    output_dir=\"Qwen_2_5_Idiom_VL_Hindi\",  # Directory to save the model\n","    num_train_epochs=3,  # Number of training epochs\n","    per_device_train_batch_size=4,  # Batch size for training\n","    per_device_eval_batch_size=4,  # Batch size for evaluation\n","    gradient_accumulation_steps=8,  # Steps to accumulate gradients\n","    gradient_checkpointing=True,  # Enable gradient checkpointing for memory efficiency\n","    # Optimizer and scheduler settings\n","    optim=\"adamw_torch_fused\",  # Optimizer type\n","    learning_rate=2e-4,  # Learning rate for training\n","    lr_scheduler_type=\"constant\",  # Type of learning rate scheduler\n","    # Logging and evaluation\n","    logging_steps=10,  # Steps interval for logging\n","    eval_steps=10,  # Steps interval for evaluation\n","    eval_strategy=\"steps\",  # Strategy for evaluation\n","    save_strategy=\"steps\",  # Strategy for saving the model\n","    save_steps=20,  # Steps interval for saving\n","    metric_for_best_model=\"eval_loss\",  # Metric to evaluate the best model\n","    greater_is_better=False,  # Whether higher metric values are better\n","    load_best_model_at_end=True,  # Load the best model after training\n","    # Mixed precision and gradient settings\n","    bf16=True,  # Use bfloat16 precision\n","    tf32=True,  # Use TensorFloat-32 precision\n","    max_grad_norm=0.3,  # Maximum norm for gradient clipping\n","    warmup_ratio=0.03,  # Ratio of total steps for warmup\n","    # Hub and reporting\n","    push_to_hub=True,  # Whether to push model to Hugging Face Hub\n","    report_to=\"wandb\",  # Reporting tool for tracking metrics\n","    # Gradient checkpointing settings\n","    gradient_checkpointing_kwargs={\"use_reentrant\": False},  # Options for gradient checkpointing\n","    # Dataset configuration\n","    dataset_text_field=\"\",  # Text field in dataset\n","    dataset_kwargs={\"skip_prepare_dataset\": True},  # Additional dataset options\n","    #max_seq_length=1024  # Maximum sequence length for input\n",")\n","\n","training_args.remove_unused_columns = False  # Keep unused columns in dataset"]},{"cell_type":"code","execution_count":null,"id":"b49e5e41-180c-411b-a11c-811a277cc487","metadata":{"id":"b49e5e41-180c-411b-a11c-811a277cc487"},"outputs":[],"source":["# Create a data collator to encode text and image pairs\n","def collate_fn(examples):\n","    # Get the texts and images, and apply the chat template\n","    texts = [processor.apply_chat_template(example, tokenize=False) for example in examples]  # Prepare texts for processing\n","    image_inputs = [process_vision_info(example)[0] for example in examples]  # Process the images to extract inputs\n","\n","    # Tokenize the texts and process the images\n","    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)  # Encode texts and images into tensors\n","\n","    # The labels are the input_ids, and we mask the padding tokens in the loss computation\n","    labels = batch[\"input_ids\"].clone()  # Clone input IDs for labels\n","    labels[labels == processor.tokenizer.pad_token_id] = -100  # Mask padding tokens in labels\n","\n","    # Ignore the image token index in the loss computation (model specific)\n","    if isinstance(processor, Qwen2_5_VLProcessor):  # Check if the processor is Qwen2VLProcessor\n","        image_tokens = [151652, 151653, 151655]  # Specific image token IDs for Qwen2VLProcessor\n","    else:\n","        image_tokens = [processor.tokenizer.convert_tokens_to_ids(processor.image_token)]  # Convert image token to ID\n","\n","    # Mask image token IDs in the labels\n","    for image_token_id in image_tokens:\n","        labels[labels == image_token_id] = -100  # Mask image token IDs in labels\n","\n","    batch[\"labels\"] = labels  # Add labels to the batch\n","\n","    return batch  # Return the prepared batch"]},{"cell_type":"code","execution_count":1,"id":"a3f082df-89cc-465a-a9bb-92f47fa708e7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"a3f082df-89cc-465a-a9bb-92f47fa708e7","executionInfo":{"status":"error","timestamp":1754384967092,"user_tz":-330,"elapsed":106,"user":{"displayName":"Sarmistha Das","userId":"02881798082792803908"}},"outputId":"93b59abb-f3ec-4b88-d170-17ad4216db43"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'trl'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2220243703.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer = SFTTrainer(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trl'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from trl import SFTTrainer\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    data_collator=collate_fn,\n","    peft_config=peft_config,\n","    # tokenizer=processor.tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"id":"120d43b8-b7ca-4e69-8eee-d164e77a8d76","metadata":{"id":"120d43b8-b7ca-4e69-8eee-d164e77a8d76","outputId":"9ad61b47-61c7-4056-c341-a2fcf29525a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='37' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 37/234 48:07 < 4:30:52, 0.01 it/s, Epoch 0.47/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>27.858400</td>\n","      <td>2.576223</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>17.888000</td>\n","      <td>1.926543</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>13.523100</td>\n","      <td>1.366189</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"]}],"source":["print(\"++++++Starting the training++++++++++\")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"2511861e-72aa-44fe-994e-49155a2f0ee6","metadata":{"id":"2511861e-72aa-44fe-994e-49155a2f0ee6"},"outputs":[],"source":["print(\"++++++Saving the Model++++++++++\")\n","trainer.save_model(training_args.output_dir)\n"]},{"cell_type":"code","execution_count":null,"id":"26e78a6e-c57b-40b3-a71e-b104f4450c71","metadata":{"id":"26e78a6e-c57b-40b3-a71e-b104f4450c71"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b4a2413f-168c-4ad8-9f43-7c12e916b61d","metadata":{"id":"b4a2413f-168c-4ad8-9f43-7c12e916b61d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"77a064a3-b275-4a63-a063-42e0bb51fabc","metadata":{"id":"77a064a3-b275-4a63-a063-42e0bb51fabc"},"outputs":[],"source":["clear_memory()\n"]}],"metadata":{"kernelspec":{"display_name":"Python (vaibhav)","language":"python","name":"vaibhav"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}