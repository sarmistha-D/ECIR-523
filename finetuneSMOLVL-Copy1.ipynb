{"cells":[{"cell_type":"code","execution_count":null,"id":"c0d7acf1-8591-463e-b815-66258f83ed7f","metadata":{"id":"c0d7acf1-8591-463e-b815-66258f83ed7f"},"outputs":[],"source":["from datasets import load_dataset\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"a0ab712f-c370-4162-afe2-adcacb2a9cfd","metadata":{"id":"a0ab712f-c370-4162-afe2-adcacb2a9cfd"},"outputs":[],"source":["print(\"++++++Reading the Dataset++++++++++\")\n","dataset = load_dataset(\"Anonymous/Final_idiom_all\",split='train') #<======== Please change the dataset in csv file."]},{"cell_type":"code","execution_count":null,"id":"06d38808-f5d0-4069-8e03-a83a3e17ab66","metadata":{"id":"06d38808-f5d0-4069-8e03-a83a3e17ab66"},"outputs":[],"source":["from huggingface_hub import login\n","\n","login(token='Anonymous_xyzkajwjewkncjqnkj') #<======= PlaceHolder"]},{"cell_type":"code","execution_count":null,"id":"b4cec1c6-af32-485f-a7a9-f8adf6757c6f","metadata":{"id":"b4cec1c6-af32-485f-a7a9-f8adf6757c6f"},"outputs":[],"source":["system_message='''You are an polyglot, who are having exceptional linguistic and cultural domain knowledge. Also, you are an native speaker of hindi, bengali and thai.'''"]},{"cell_type":"code","execution_count":null,"id":"e6e8e226-f1af-44e4-9ec6-e84ba7484747","metadata":{"id":"e6e8e226-f1af-44e4-9ec6-e84ba7484747"},"outputs":[],"source":["def format_data(sample):\n","    return [\n","        {\n","            \"role\": \"system\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": system_message\n","                }\n","            ],\n","        },\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"image\",\n","                    \"image\": sample[\"image\"],\n","                },\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": sample['Actual idiom'],\n","                }\n","            ],\n","        },\n","        {\n","            \"role\": \"assistant\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": sample[\"Descriptive Meaning(Human Annotation)\"]\n","                }\n","            ],\n","        },\n","    ]"]},{"cell_type":"code","execution_count":null,"id":"5d62db64-f863-451a-b8f5-29e286306707","metadata":{"id":"5d62db64-f863-451a-b8f5-29e286306707"},"outputs":[],"source":["print(dataset)"]},{"cell_type":"code","execution_count":null,"id":"98e26f04-7523-48d2-b85f-c8737831eb85","metadata":{"id":"98e26f04-7523-48d2-b85f-c8737831eb85"},"outputs":[],"source":["# print(dataset[3132])\n","# print(len(dataset))"]},{"cell_type":"code","execution_count":null,"id":"cba40892-aa71-4186-9386-06bc31e0b481","metadata":{"id":"cba40892-aa71-4186-9386-06bc31e0b481"},"outputs":[],"source":["print(\"++++++Seperating the Dataset on Lingual Basis++++++++++\")\n","dataset_hindi = dataset.select(range(0,1277))\n","dataset_thai = dataset.select(range(1382,3133))\n","bengali_indicies = list(range(1277,1382))+list(range(3133,3533))\n","dataset_bengali= dataset.select(bengali_indicies)"]},{"cell_type":"code","execution_count":null,"id":"b3f3186b-4da4-44b5-98d9-cb35f41b2d51","metadata":{"id":"b3f3186b-4da4-44b5-98d9-cb35f41b2d51"},"outputs":[],"source":["from datasets import Dataset,concatenate_datasets"]},{"cell_type":"code","execution_count":null,"id":"6b9fc488-0948-4e31-8beb-70ccaf1838f5","metadata":{"id":"6b9fc488-0948-4e31-8beb-70ccaf1838f5"},"outputs":[],"source":["def split_dataset(dataset1):\n","    train_testvalid = dataset1.train_test_split(test_size=0.3, seed=42)\n","    train_dataset = train_testvalid['train']\n","    temp_dataset = train_testvalid['test']\n","\n","    # Step 2: Split the remaining 30% into 2/3 (validation) and 1/3 (test)\n","    # 2/3 of 30% = 20%, 1/3 of 30% = 10%\n","    val_test = temp_dataset.train_test_split(test_size=2/3, seed=42)\n","    val_dataset = val_test['train']    # 20%\n","    test_dataset = val_test['test']    # 10%\n","\n","    return train_dataset, val_dataset, test_dataset"]},{"cell_type":"code","execution_count":null,"id":"008173e7-07f3-44f8-a90d-81ec70f3a187","metadata":{"id":"008173e7-07f3-44f8-a90d-81ec70f3a187"},"outputs":[],"source":["print(\"++++++Splitting the Dataset and Merging++++++++++\")\n","train_dataset_hindi, val_dataset_hindi, test_dataset_hindi = split_dataset(dataset_hindi)\n","train_dataset_thai, val_dataset_thai, test_dataset_thai = split_dataset(dataset_thai)\n","train_dataset_bengali, val_dataset_bengali, test_dataset_bengali = split_dataset(dataset_bengali)\n","\n","\n","#Merging the dataset\n","train_dataset_final = concatenate_datasets([train_dataset_hindi,train_dataset_thai,train_dataset_bengali])\n","val_dataset_final = concatenate_datasets([val_dataset_hindi,val_dataset_thai,val_dataset_bengali])\n","test_dataset_final = concatenate_datasets([test_dataset_hindi,test_dataset_thai,test_dataset_bengali])\n","\n","print(len(train_dataset_final),len(val_dataset_final),len(test_dataset_final))\n","\n","\n","# dataset.save_to_disk(\"test_dataset_final\")"]},{"cell_type":"code","execution_count":null,"id":"6c278b2e-0698-4ed3-a873-3f34b67380f7","metadata":{"id":"6c278b2e-0698-4ed3-a873-3f34b67380f7"},"outputs":[],"source":["print(\"++++++Converting the Dataset to JSON format++++++++++\")\n","train_dataset = [format_data(sample) for sample in train_dataset_final]\n","eval_dataset = [format_data(sample) for sample in val_dataset_final]\n","test_dataset = [format_data(sample) for sample in test_dataset_final]"]},{"cell_type":"code","execution_count":null,"id":"fbba9081-ca0e-4455-bfc0-c8a1bce4cc33","metadata":{"id":"fbba9081-ca0e-4455-bfc0-c8a1bce4cc33"},"outputs":[],"source":["print(train_dataset[2000])"]},{"cell_type":"code","execution_count":null,"id":"4f8aca81-a2b5-4028-92dd-96c59f2e16a2","metadata":{"id":"4f8aca81-a2b5-4028-92dd-96c59f2e16a2"},"outputs":[],"source":["import torch\n","from transformers import Idefics3ForConditionalGeneration, AutoProcessor\n","\n","model_id = \"HuggingFaceTB/SmolVLM-Instruct\"\n","print(\"++++++Importing Models++++++++++\")\n"]},{"cell_type":"code","execution_count":null,"id":"83e07bec-2b26-4aaf-9774-b4c31f0d12e5","metadata":{"id":"83e07bec-2b26-4aaf-9774-b4c31f0d12e5"},"outputs":[],"source":["print(\"++++++Cleaning up space++++++++++\")\n","import gc\n","import time\n","\n","def clear_memory():\n","    # Delete variables if they exist in the current global scope\n","    if 'inputs' in globals(): del globals()['inputs']\n","    if 'model' in globals(): del globals()['model']\n","    if 'processor' in globals(): del globals()['processor']\n","    if 'trainer' in globals(): del globals()['trainer']\n","    if 'peft_model' in globals(): del globals()['peft_model']\n","    if 'bnb_config' in globals(): del globals()['bnb_config']\n","    time.sleep(2)\n","\n","    # Garbage collection and clearing CUDA memory\n","    gc.collect()\n","    time.sleep(2)\n","    torch.cuda.empty_cache()\n","    torch.cuda.synchronize()\n","    time.sleep(2)\n","    gc.collect()\n","    time.sleep(2)\n","\n","    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n","\n","clear_memory()"]},{"cell_type":"code","execution_count":null,"id":"f325ef83-4fe0-4f8a-af30-103a4a5789e7","metadata":{"id":"f325ef83-4fe0-4f8a-af30-103a4a5789e7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6e9b0cc2-4f57-4966-9d07-a776ea51f08a","metadata":{"id":"6e9b0cc2-4f57-4966-9d07-a776ea51f08a"},"outputs":[],"source":["print(\"++++++setting up BitsAndBytesConfig++++++++++\")\n","from transformers import BitsAndBytesConfig\n","\n","# BitsAndBytesConfig int-4 config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# Load model and tokenizer\n","model = Idefics3ForConditionalGeneration.from_pretrained(\n","    model_id,\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n","    quantization_config=bnb_config,\n","    _attn_implementation=\"flash_attention_2\",\n",")\n","processor = AutoProcessor.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":null,"id":"afd3eadf-2261-4f73-8014-88a852ed8fe3","metadata":{"id":"afd3eadf-2261-4f73-8014-88a852ed8fe3"},"outputs":[],"source":["from peft import LoraConfig, get_peft_model\n","\n","# Configure LoRA\n","peft_config = LoraConfig(\n","    r=8,\n","    lora_alpha=8,\n","    lora_dropout=0.1,\n","    target_modules=['down_proj','o_proj','k_proj','q_proj','gate_proj','up_proj','v_proj'],\n","    use_dora=True,\n","    init_lora_weights=\"gaussian\"\n",")\n","\n","# Apply PEFT model adaptation\n","peft_model = get_peft_model(model, peft_config)\n","\n","# Print trainable parameters\n","peft_model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"id":"6ea900a3-f4e1-46a0-b9f6-b9855e1b8344","metadata":{"id":"6ea900a3-f4e1-46a0-b9f6-b9855e1b8344"},"outputs":[],"source":["from trl import SFTConfig\n","\n","# Configure training arguments using SFTConfig\n","training_args = SFTConfig(\n","    output_dir=\"SmolVLM_Idiom_VL\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=8,\n","    warmup_steps=50,\n","    learning_rate=2e-4,\n","    weight_decay=0.01,\n","    logging_steps=10,\n","    save_strategy=\"steps\",\n","    save_steps=20,\n","    # save_total_limit=1,\n","    optim=\"adamw_torch_fused\",\n","    bf16=True,\n","    push_to_hub=True,\n","    report_to=\"wandb\",\n","    remove_unused_columns=False,\n","    gradient_checkpointing=True,\n","    dataset_text_field=\"\",\n","    dataset_kwargs={\"skip_prepare_dataset\": True},\n",")"]},{"cell_type":"code","execution_count":null,"id":"51c69d63-6d5d-40e9-bfb1-23f603db12e0","metadata":{"id":"51c69d63-6d5d-40e9-bfb1-23f603db12e0"},"outputs":[],"source":["print(\"++++++connecting to wanb++++++++++\")\n","import wandb\n","\n","wandb.init(\n","    project=\"SmolVLM_Idiom_VL\",  # change this\n","    name=\"SmolVLM_Idiom_VL\",  # change this\n","    config=training_args,\n",")"]},{"cell_type":"code","execution_count":null,"id":"b275503f-94ac-4dfe-94a9-2a81ad27bab9","metadata":{"id":"b275503f-94ac-4dfe-94a9-2a81ad27bab9"},"outputs":[],"source":["image_token_id = processor.tokenizer.additional_special_tokens_ids[\n","            processor.tokenizer.additional_special_tokens.index(\"<image>\")]\n","\n","def collate_fn(examples):\n","    texts = [processor.apply_chat_template(example, tokenize=False) for example in examples]\n","\n","    image_inputs = []\n","    for example in examples:\n","      image = example[1]['content'][0]['image']\n","      if image.mode != 'RGB':\n","          image = image.convert('RGB')\n","      image_inputs.append([image])\n","\n","    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n","    labels = batch[\"input_ids\"].clone()\n","    labels[labels == processor.tokenizer.pad_token_id] = -100  # Mask padding tokens in labels\n","    labels[labels == image_token_id] = -100  # Mask image token IDs in labels\n","\n","    batch[\"labels\"] = labels\n","\n","    return batch"]},{"cell_type":"code","execution_count":null,"id":"a3f082df-89cc-465a-a9bb-92f47fa708e7","metadata":{"id":"a3f082df-89cc-465a-a9bb-92f47fa708e7"},"outputs":[],"source":["from trl import SFTTrainer\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    data_collator=collate_fn,\n","    peft_config=peft_config,\n","    processing_class=processor.tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"id":"120d43b8-b7ca-4e69-8eee-d164e77a8d76","metadata":{"id":"120d43b8-b7ca-4e69-8eee-d164e77a8d76"},"outputs":[],"source":["print(\"++++++Starting the training++++++++++\")\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"2511861e-72aa-44fe-994e-49155a2f0ee6","metadata":{"id":"2511861e-72aa-44fe-994e-49155a2f0ee6"},"outputs":[],"source":["print(\"++++++Saving the Model++++++++++\")\n","trainer.save_model(training_args.output_dir)\n"]},{"cell_type":"code","execution_count":null,"id":"77a064a3-b275-4a63-a063-42e0bb51fabc","metadata":{"id":"77a064a3-b275-4a63-a063-42e0bb51fabc"},"outputs":[],"source":["clear_memory()\n"]},{"cell_type":"code","execution_count":null,"id":"820a40aa-a06c-4780-8cbf-cf02d0106cc6","metadata":{"id":"820a40aa-a06c-4780-8cbf-cf02d0106cc6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}